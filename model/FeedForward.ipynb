{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feed-Forward Networks\n",
        "\n",
        "Position-wise feed-forward networks that process each position independently.\n",
        "\n",
        "In this notebook, you'll implement the feed-forward layer used in transformers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Position-wise Feed-Forward Network\n",
        "\n",
        "FFN(x) = max(0, xWâ‚ + bâ‚)Wâ‚‚ + bâ‚‚\n",
        "\n",
        "Two linear transformations with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Initialize PositionwiseFeedForward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise feed-forward network.\n",
        "    \n",
        "    Applies two linear transformations with ReLU activation:\n",
        "    FFN(x) = max(0, xWâ‚ + bâ‚)Wâ‚‚ + bâ‚‚\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¯ Practice: Implement your own `__init__`\n",
        "\n",
        "Create two linear layers:\n",
        "- First: d_model â†’ d_ff (expand)\n",
        "- Second: d_ff â†’ d_model (project back)\n",
        "- Don't forget dropout!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your implementation here\n",
        "# class MyPositionwiseFeedForward(nn.Module):\n",
        "#     def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
        "#         # Your code here\n",
        "#         pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Apply feed-forward network.\n",
        "        \n",
        "        Args:\n",
        "            x: Input of shape (batch, seq, d_model)\n",
        "            \n",
        "        Returns:\n",
        "            Output of shape (batch, seq, d_model)\n",
        "        \"\"\"\n",
        "        # First linear + ReLU\n",
        "        x = F.relu(self.w_1(x))\n",
        "        # Dropout\n",
        "        x = self.dropout(x)\n",
        "        # Second linear\n",
        "        x = self.w_2(x)\n",
        "        return x\n",
        "\n",
        "# Add forward method to the class\n",
        "PositionwiseFeedForward.forward = forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¯ Practice: Implement your own `forward`\n",
        "\n",
        "Steps:\n",
        "1. Apply first linear layer\n",
        "2. Apply ReLU activation\n",
        "3. Apply dropout\n",
        "4. Apply second linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your implementation here\n",
        "# def my_forward(self, x):\n",
        "#     # Your code here\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Feed-Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ff = PositionwiseFeedForward(d_model=512, d_ff=2048)\n",
        "x = torch.randn(2, 32, 512)  # (batch=2, seq=32, d_model=512)\n",
        "out = ff(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {out.shape}\")\n",
        "print(f\"\\nâœ… Feed-forward network works!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}